services:
  # Main API Service (FastAPI): The heart of the application, handles data ingestion,
  # ML endpoints, and serves the business logic. Depends on DB and Redis for core functionality.
  # Uses toxiproxy connections for chaos engineering and resilience testing.
  api:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_api
    ports:
      - "8000:8000"  # FastAPI backend
    environment:
      - PYTHONPATH=/app
      - DISABLE_CHROMADB=true  # Disable ChromaDB for now due to SQLite version
      - MLFLOW_S3_ENDPOINT_URL=http://mlflow:5000  # Force MLflow client to proxy artifact access via HTTP
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"  # Match host user for consistent file ownership across containers
    volumes:
      - ./logs:/app/logs  # Mount logs directory
      - ./mlflow_data:/mlruns        # MLflow artifact store for model loading (matches MLflow container)
    entrypoint: ["uvicorn", "apps.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - smart-maintenance-network

  # Streamlit UI Service: Interactive web interface for data visualization, model monitoring,
  # and system administration. Communicates with the API service for data access and operations.
  # Provides real-time dashboards and user-friendly interfaces for predictive maintenance insights.
  ui:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_ui
    ports:
      - "8501:8501"  # Streamlit UI
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
      - PYTHONPATH=/app
      - API_BASE_URL=http://api:8000  # Internal communication with API
    env_file:
      - .env
    depends_on:
      api:
        condition: service_healthy
      db:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs  # Mount logs directory
    command: ["streamlit", "run", "ui/streamlit_app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - smart-maintenance-network

  # TimescaleDB Database: Stores all time-series sensor data and application metadata.
  # TimescaleDB provides optimized time-series operations, hypertables, and continuous aggregates.
  # The 'pg_data' volume ensures data persistence across container restarts and deployments.
  db:
    image: timescale/timescaledb:latest-pg14
    container_name: smart_maintenance_db
    environment:
      POSTGRES_DB: smart_maintenance_db
      POSTGRES_USER: smart_user
      POSTGRES_PASSWORD: strong_password
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"  # Use different port to avoid conflicts
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./infrastructure/docker/init-scripts:/docker-entrypoint-initdb.d
    networks:
      - smart-maintenance-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U smart_user -d smart_maintenance_db"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Redis Service: Provides distributed caching, session management, and idempotency control.
  # Essential for preventing duplicate data ingestion and enabling event-driven architecture.
  # Supports pub/sub messaging for agent communication and real-time notifications.
  redis:
    image: redis:7.2-alpine
    container_name: smart_maintenance_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    networks:
      - smart-maintenance-network

  # Toxiproxy Service: Chaos engineering proxy for simulating network failures and latency.
  # Sits between services to enable resilience testing by injecting faults, delays, and timeouts.
  # Critical for validating system behavior under adverse network conditions.
  toxiproxy:
    image: ghcr.io/shopify/toxiproxy:2.5.0
    container_name: smart_maintenance_toxiproxy
    restart: unless-stopped
    ports:
      - "8474:8474"  # Toxiproxy API
      - "5434:5434"  # Proxied PostgreSQL port (changed to avoid conflict)
      - "6380:6380"  # Proxied Redis port
    networks:
      - smart-maintenance-network

  # Toxiproxy Initialization Service: One-time setup service that configures proxy rules
  # and establishes connections between services and Toxiproxy for chaos engineering.
  # Runs once per stack startup to ensure proper proxy configuration.
  toxiproxy_init:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_toxiproxy_init
    command: ["./scripts/toxiproxy_init.sh"]
    depends_on:
      toxiproxy:
        condition: service_started
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: "no"  # Only run once per stack startup
    networks:
      - smart-maintenance-network

  # MLflow Tracking Server: Centralized ML experiment tracking, model versioning, and artifact storage.
  # Provides REST API for logging experiments, storing model artifacts, and managing ML lifecycle.
  # The 'mlflow_data' and 'mlflow_db' volumes are crucial for preserving ML models and experiment history.
  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: smart_maintenance_mlflow
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=${MLFLOW_BACKEND_STORE_URI}
      - MLFLOW_ARTIFACT_ROOT=${MLFLOW_ARTIFACT_ROOT}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    env_file:
      - .env
    user: "1000:1000"  # Match host user for consistent file ownership with API container
    # Ensure backend store (SQLite) and artifact root map to host for persistence
    volumes:
      - ./mlflow_data:/mlruns        # Artifact store
      - ./mlflow_db:/mlflow_db       # SQLite backend store (mlflow.db lives here)
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - smart-maintenance-network

  # Jupyter Notebook Runner: Automated execution service for ML training notebooks and experiments.
  # Runs parameterized notebooks using Papermill for reproducible ML pipeline execution.
  # Shares volumes with other services to access datasets and store experiment results.
  notebook_runner:
    build:
      context: .
      dockerfile: Dockerfile.ml
    container_name: smart_maintenance_notebook_runner
    command: >
      sh -c "papermill notebooks/$${NOTEBOOK_FILE}.ipynb notebooks/$${NOTEBOOK_FILE}_output.ipynb"
    environment:
      - DOCKER_ENV=true
      - NOTEBOOK_FILE=02_anomaly_isolation_forest
    user: "1000:1000"  # Match host user for consistent file ownership with API container
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./apps:/app/apps
      - ./docs:/app/docs
      - ./mlflow_data:/mlruns        # MLflow artifact store (matches other containers)
    networks:
      - smart-maintenance-network
    depends_on:
      - mlflow

  # ML Utility Container: General-purpose container for ad-hoc ML operations and load testing.
  # Provides access to full project directory for running scripts, Locust tests, and data analysis.
  # Used for development tasks, debugging, and manual ML operations outside of automated pipelines.
  ml:
    build:
      context: .
      dockerfile: Dockerfile.ml
    container_name: smart_maintenance_ml
    command: bash
    environment:
      - DOCKER_ENV=true
    user: "1000:1000"  # Match host user for consistent file ownership
    volumes:
      - .:/app  # Mount entire project directory
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./apps:/app/apps
      - ./docs:/app/docs
      - ./mlflow_data:/app/mlflow_data
    networks:
      - smart-maintenance-network
    depends_on:
      - mlflow

  # Automated Drift Detection Agent: Continuously monitors ML model performance and data drift.
  # Runs scheduled checks (every 6 hours) to detect statistical changes in data distribution.
  # Publishes drift events to Redis for triggering automated model retraining workflows.
  drift_agent:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_drift_agent
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@toxiproxy:5434/smart_maintenance_db
      - REDIS_URL=redis://redis:6379/0
      - API_BASE_URL=http://api:8000
      - PYTHONPATH=/app
      - DRIFT_CHECK_ENABLED=true
      - DRIFT_CHECK_SCHEDULE=0 */6 * * *  # Every 6 hours
      - DRIFT_THRESHOLD=0.05
      - SENSORS_TO_MONITOR=demo-sensor-001
      - RUN_STARTUP_CHECK=true
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"
    volumes:
      - ./logs:/app/logs
      - ./mlflow_data:/mlruns
    command: ["python", "scripts/run_drift_check_agent.py"]
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - smart-maintenance-network

  # Model Retraining Agent: Event-driven service that automatically retrains ML models
  # when drift is detected. Implements cooldown periods and concurrency controls to prevent
  # resource exhaustion. Coordinates with MLflow for model versioning and deployment.
  retrain_agent:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_retrain_agent
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@toxiproxy:5434/smart_maintenance_db
      - REDIS_URL=redis://redis:6379/0
      - PYTHONPATH=/app:/app/.venv/lib/python3.11/site-packages
      - PATH=/app/.venv/bin:$PATH
      - RETRAINING_ENABLED=true
      - RETRAINING_COOLDOWN_HOURS=24
      - MAX_CONCURRENT_RETRAINING=1
      - MODELS_TO_RETRAIN=anomaly:train-anomaly,forecast:train-forecast
      - TRAINING_TIMEOUT_MINUTES=60
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"
    volumes:
      - ./logs:/app/logs
      - ./mlflow_data:/mlruns
      - .:/app  # Full access for make commands
    command: ["/app/.venv/bin/python", "scripts/retrain_models_on_drift.py"]
    networks:
      - smart-maintenance-network

  # --- Future Microservices: Uncomment when MICROSERVICE_MIGRATION_STRATEGY triggers are met ---
  # 
  # # Prediction Service - Handles ML model predictions and inference
  # prediction_service:
  #   build:
  #     context: services/prediction_service
  #     dockerfile: Dockerfile
  #   container_name: smart_maintenance_prediction_service
  #   ports:
  #     - "8001:8001"  # Prediction service API
  #   environment:
  #     - MLFLOW_TRACKING_URI=http://mlflow:5000
  #     - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
  #   env_file:
  #     - .env
  #   user: "1000:1000"
  #   volumes:
  #     - ./mlflow_data:/mlruns  # MLflow artifact store access
  #     - ./logs:/app/logs      # Shared logging directory
  #   networks:
  #     - smart-maintenance-network
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     mlflow:
  #       condition: service_started
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s
  #
  # # Anomaly Service - Handles drift detection and anomaly monitoring
  # anomaly_service:
  #   build:
  #     context: services/anomaly_service
  #     dockerfile: Dockerfile
  #   container_name: smart_maintenance_anomaly_service
  #   ports:
  #     - "8002:8002"  # Anomaly service API
  #   environment:
  #     - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
  #     - REDIS_URL=redis://redis:6379/0
  #   env_file:
  #     - .env
  #   user: "1000:1000"
  #   volumes:
  #     - ./logs:/app/logs      # Shared logging directory
  #   networks:
  #     - smart-maintenance-network
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s

volumes:
  pg_data:
    name: smart_maintenance_pg_data
  redis_data:
    name: smart_maintenance_redis_data

networks:
  smart-maintenance-network:
    driver: bridge
