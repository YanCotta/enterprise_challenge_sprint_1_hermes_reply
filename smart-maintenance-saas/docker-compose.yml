services:
  # FastAPI Backend Service
  api:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_api
    ports:
      - "8000:8000"  # FastAPI backend
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@toxiproxy:5434/smart_maintenance_db
      - REDIS_URL=redis://toxiproxy:6380/0
      - PYTHONPATH=/app
      - DISABLE_CHROMADB=true  # Disable ChromaDB for now due to SQLite version
      - MLFLOW_S3_ENDPOINT_URL=http://mlflow:5000  # Force MLflow client to proxy artifact access via HTTP
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"  # Match host user for consistent file ownership across containers
    volumes:
      - ./logs:/app/logs  # Mount logs directory
      - ./mlflow_data:/mlruns        # MLflow artifact store for model loading (matches MLflow container)
    entrypoint: ["/app/entrypoint.sh"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - smart-maintenance-network

  # Streamlit UI Service
  ui:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_ui
    ports:
      - "8501:8501"  # Streamlit UI
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
      - PYTHONPATH=/app
      - API_BASE_URL=http://api:8000  # Internal communication with API
    env_file:
      - .env
    depends_on:
      api:
        condition: service_healthy
      db:
        condition: service_healthy
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs  # Mount logs directory
    command: ["streamlit", "run", "ui/streamlit_app.py", "--server.port", "8501", "--server.address", "0.0.0.0"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - smart-maintenance-network

  # Database Service
  db:
    image: timescale/timescaledb:latest-pg14
    container_name: smart_maintenance_db
    environment:
      POSTGRES_DB: smart_maintenance_db
      POSTGRES_USER: smart_user
      POSTGRES_PASSWORD: strong_password
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5433:5432"  # Use different port to avoid conflicts
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./infrastructure/docker/init-scripts:/docker-entrypoint-initdb.d
    networks:
      - smart-maintenance-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U smart_user -d smart_maintenance_db"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Redis Service for distributed caching and idempotency
  redis:
    image: redis:7.2-alpine
    container_name: smart_maintenance_redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    networks:
      - smart-maintenance-network

  # Toxiproxy for chaos engineering and network failure simulation
  toxiproxy:
    image: ghcr.io/shopify/toxiproxy:2.5.0
    container_name: smart_maintenance_toxiproxy
    restart: unless-stopped
    ports:
      - "8474:8474"  # Toxiproxy API
      - "5434:5434"  # Proxied PostgreSQL port (changed to avoid conflict)
      - "6380:6380"  # Proxied Redis port
    networks:
      - smart-maintenance-network

  # Toxiproxy Initialization Service - Automatically configures proxies on startup
  toxiproxy_init:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_toxiproxy_init
    command: ["./scripts/toxiproxy_init.sh"]
    depends_on:
      toxiproxy:
        condition: service_started
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: "no"  # Only run once per stack startup
    networks:
      - smart-maintenance-network

  # MLflow Service (hardened)
  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: smart_maintenance_mlflow
    restart: unless-stopped
    ports:
      - "5000:5000"
    user: "1000:1000"  # Match host user for consistent file ownership with API container
    # Ensure backend store (SQLite) and artifact root map to host for persistence
    volumes:
      - ./mlflow_data:/mlruns        # Artifact store
      - ./mlflow_db:/mlflow_db       # SQLite backend store (mlflow.db lives here)
    networks:
      - smart-maintenance-network

  # One-off notebook runner service for ML training / experimentation
  notebook_runner:
    build:
      context: .
      dockerfile: Dockerfile.ml
    container_name: smart_maintenance_notebook_runner
    command: >
      sh -c "papermill notebooks/$${NOTEBOOK_FILE}.ipynb notebooks/$${NOTEBOOK_FILE}_output.ipynb"
    environment:
      - DOCKER_ENV=true
      - NOTEBOOK_FILE=02_anomaly_isolation_forest
    user: "1000:1000"  # Match host user for consistent file ownership with API container
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./apps:/app/apps
      - ./docs:/app/docs
      - ./mlflow_data:/mlruns        # MLflow artifact store (matches other containers)
    networks:
      - smart-maintenance-network
    depends_on:
      - mlflow

  # Generic ML utility container (used for ad-hoc commands like Locust load testing)
  ml:
    build:
      context: .
      dockerfile: Dockerfile.ml
    container_name: smart_maintenance_ml
    command: bash
    environment:
      - DOCKER_ENV=true
    user: "1000:1000"  # Match host user for consistent file ownership
    volumes:
      - .:/app  # Mount entire project directory
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./apps:/app/apps
      - ./docs:/app/docs
      - ./mlflow_data:/app/mlflow_data
    networks:
      - smart-maintenance-network
    depends_on:
      - mlflow

  # Automated Drift Detection Agent
  drift_agent:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_drift_agent
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@toxiproxy:5434/smart_maintenance_db
      - REDIS_URL=redis://redis:6379/0
      - PYTHONPATH=/app
      - DRIFT_CHECK_ENABLED=true
      - DRIFT_CHECK_SCHEDULE=0 */6 * * *  # Every 6 hours
      - DRIFT_THRESHOLD=0.05
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"
    volumes:
      - ./logs:/app/logs
      - ./mlflow_data:/mlruns
    command: ["python", "scripts/run_drift_check_agent.py"]
    networks:
      - smart-maintenance-network

  # Model Retraining Agent (triggered by drift events)
  retrain_agent:
    build: .
    image: smart-maintenance-saas:latest
    container_name: smart_maintenance_retrain_agent
    environment:
      - DATABASE_URL=postgresql://smart_user:strong_password@toxiproxy:5434/smart_maintenance_db
      - REDIS_URL=redis://redis:6379/0
      - PYTHONPATH=/app
      - RETRAINING_ENABLED=true
      - RETRAINING_COOLDOWN_HOURS=24
      - MAX_CONCURRENT_RETRAINING=1
      - MODELS_TO_RETRAIN=anomaly:train-anomaly,forecast:train-forecast
      - TRAINING_TIMEOUT_MINUTES=60
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started
      toxiproxy_init:
        condition: service_completed_successfully
    restart: unless-stopped
    user: "1000:1000"
    volumes:
      - ./logs:/app/logs
      - ./mlflow_data:/mlruns
      - .:/app  # Full access for make commands
    command: ["python", "scripts/retrain_models_on_drift.py"]
    networks:
      - smart-maintenance-network

  # --- Future Microservices: Uncomment when MICROSERVICE_MIGRATION_STRATEGY triggers are met ---
  # 
  # # Prediction Service - Handles ML model predictions and inference
  # prediction_service:
  #   build:
  #     context: services/prediction_service
  #     dockerfile: Dockerfile
  #   container_name: smart_maintenance_prediction_service
  #   ports:
  #     - "8001:8001"  # Prediction service API
  #   environment:
  #     - MLFLOW_TRACKING_URI=http://mlflow:5000
  #     - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
  #   env_file:
  #     - .env
  #   user: "1000:1000"
  #   volumes:
  #     - ./mlflow_data:/mlruns  # MLflow artifact store access
  #     - ./logs:/app/logs      # Shared logging directory
  #   networks:
  #     - smart-maintenance-network
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     mlflow:
  #       condition: service_started
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s
  #
  # # Anomaly Service - Handles drift detection and anomaly monitoring
  # anomaly_service:
  #   build:
  #     context: services/anomaly_service
  #     dockerfile: Dockerfile
  #   container_name: smart_maintenance_anomaly_service
  #   ports:
  #     - "8002:8002"  # Anomaly service API
  #   environment:
  #     - DATABASE_URL=postgresql://smart_user:strong_password@db:5432/smart_maintenance_db
  #     - REDIS_URL=redis://redis:6379/0
  #   env_file:
  #     - .env
  #   user: "1000:1000"
  #   volumes:
  #     - ./logs:/app/logs      # Shared logging directory
  #   networks:
  #     - smart-maintenance-network
  #   depends_on:
  #     db:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #   restart: unless-stopped
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 40s

volumes:
  pg_data:
    name: smart_maintenance_pg_data
  redis_data:
    name: smart_maintenance_redis_data

networks:
  smart-maintenance-network:
    driver: bridge
