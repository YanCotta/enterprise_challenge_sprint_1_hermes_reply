{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from prophet import Prophet\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import logging\n",
    "import os\n",
    "from apps.ml.features import SensorFeatureTransformer\n",
    "\n",
    "logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.ERROR)\n",
    "\n",
    "tracking_uri = \"http://mlflow:5000\" if os.getenv(\"DOCKER_ENV\") == \"true\" else \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"Forecasting Models\")\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Preparation (Consistent for both models) ---\n",
    "df = pd.read_csv('data/sensor_data.csv', parse_dates=['timestamp'])\n",
    "df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "sensor_id = 'sensor-001'\n",
    "df_sensor = df[df['sensor_id'] == sensor_id].copy()\n",
    "\n",
    "# 80/20 Train/Test Split\n",
    "split_point = int(len(df_sensor) * 0.8)\n",
    "train_df_raw = df_sensor.iloc[:split_point]\n",
    "test_df_raw = df_sensor.iloc[split_point:]\n",
    "\n",
    "y_true = test_df_raw['value'].values\n",
    "\n",
    "print(f\"Data prepared for sensor: {sensor_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Prophet Hyperparameter Tuning ---\n",
    "print(\"\\n--- Starting Prophet Tuning ---\")\n",
    "\n",
    "# Define a simple grid of hyperparameters to test\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.01, 0.05, 0.1],\n",
    "    'seasonality_prior_scale': [1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Prepare data for Prophet\n",
    "train_df_prophet = train_df_raw[['timestamp', 'value']].rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "\n",
    "for cps in param_grid['changepoint_prior_scale']:\n",
    "    for sps in param_grid['seasonality_prior_scale']:\n",
    "        with mlflow.start_run(run_name=f\"Prophet_Tuning_cps_{cps}_sps_{sps}\", nested=True):\n",
    "            params = {'changepoint_prior_scale': cps, 'seasonality_prior_scale': sps}\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", \"Prophet_Tuned\")\n",
    "\n",
    "            model = Prophet(**params, daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False)\n",
    "            model.fit(train_df_prophet)\n",
    "            \n",
    "            future_df = model.make_future_dataframe(periods=len(test_df_raw), freq='5min')\n",
    "            forecast_df = model.predict(future_df)\n",
    "            y_pred = forecast_df['yhat'][-len(test_df_raw):].values\n",
    "            \n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_params = params\n",
    "                # Log the best model so far\n",
    "                mlflow.prophet.log_model(model, \"best_prophet_model\")\n",
    "                mlflow.set_tag(\"status\", \"best_candidate\")\n",
    "\n",
    "print(f\"Best Prophet MAE: {best_mae:.4f} with params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Challenger Model: LightGBM with Lag Features ---\n",
    "print(\"\\n--- Starting LightGBM Challenger Model ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_Challenger_v1\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    \n",
    "    # --- Feature Engineering ---\n",
    "    # Create lag features for forecasting the next value\n",
    "    feature_transformer = SensorFeatureTransformer(n_lags=12, scale_columns=['value'])\n",
    "    \n",
    "    # Transform train data\n",
    "    X_train_transformed = feature_transformer.fit_transform(train_df_raw)\n",
    "    # Create target: next value (shift -1 means we predict the next value)\n",
    "    y_train_full = train_df_raw['value'].shift(-1)\n",
    "    \n",
    "    # Remove the last row since it doesn't have a target (NaN after shift)\n",
    "    X_train_clean = X_train_transformed.iloc[:-1]\n",
    "    y_train_clean = y_train_full.iloc[:-1]\n",
    "    \n",
    "    # Transform test data\n",
    "    X_test_transformed = feature_transformer.transform(test_df_raw)\n",
    "    y_test_full = test_df_raw['value'].shift(-1)\n",
    "    \n",
    "    # Remove the last row since it doesn't have a target\n",
    "    X_test_clean = X_test_transformed.iloc[:-1]\n",
    "    y_test_clean = y_test_full.iloc[:-1]\n",
    "    \n",
    "    # Check for any remaining NaN values and handle them\n",
    "    print(f\"NaN values in X_train: {X_train_clean.isna().sum().sum()}\")\n",
    "    print(f\"NaN values in y_train: {y_train_clean.isna().sum()}\")\n",
    "    print(f\"NaN values in X_test: {X_test_clean.isna().sum().sum()}\")\n",
    "    print(f\"NaN values in y_test: {y_test_clean.isna().sum()}\")\n",
    "    \n",
    "    # Drop any remaining NaN rows\n",
    "    if X_train_clean.isna().any().any() or y_train_clean.isna().any():\n",
    "        valid_train_idx = ~(X_train_clean.isna().any(axis=1) | y_train_clean.isna())\n",
    "        X_train_clean = X_train_clean[valid_train_idx]\n",
    "        y_train_clean = y_train_clean[valid_train_idx]\n",
    "        print(f\"Dropped {(~valid_train_idx).sum()} training rows with NaN\")\n",
    "    \n",
    "    if X_test_clean.isna().any().any() or y_test_clean.isna().any():\n",
    "        valid_test_idx = ~(X_test_clean.isna().any(axis=1) | y_test_clean.isna())\n",
    "        X_test_clean = X_test_clean[valid_test_idx]\n",
    "        y_test_clean = y_test_clean[valid_test_idx]\n",
    "        print(f\"Dropped {(~valid_test_idx).sum()} test rows with NaN\")\n",
    "    \n",
    "    print(f\"Final training set size: {len(X_train_clean)}\")\n",
    "    print(f\"Final test set size: {len(X_test_clean)}\")\n",
    "    \n",
    "    # --- Model Training ---\n",
    "    lgbm = lgb.LGBMRegressor(random_state=42, verbosity=-1)\n",
    "    mlflow.log_params(lgbm.get_params())\n",
    "    lgbm.fit(X_train_clean, y_train_clean)\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    y_pred_lgbm = lgbm.predict(X_test_clean)\n",
    "    mae_lgbm = mean_absolute_error(y_test_clean, y_pred_lgbm)\n",
    "    mlflow.log_metric(\"mae\", mae_lgbm)\n",
    "    \n",
    "    print(f\"LightGBM MAE: {mae_lgbm:.4f}\")\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(lgbm, \"model\", registered_model_name=\"lightgbm_forecaster_challenger\")\n",
    "\n",
    "print(\"\\n--- Experiment session complete! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
