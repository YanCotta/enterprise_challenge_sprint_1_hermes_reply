{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebed59f8",
   "metadata": {},
   "source": [
    "# MLflow Validation Test - Self-Contained Model Registration\n",
    "\n",
    "This notebook generates synthetic data and registers a simple model to validate our MLflow infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48182c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41afde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic sensor data\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Create features that mimic sensor readings\n",
    "data = {\n",
    "    'temperature': np.random.normal(25, 5, n_samples),\n",
    "    'vibration': np.random.normal(0.5, 0.2, n_samples),\n",
    "    'pressure': np.random.normal(100, 15, n_samples),\n",
    "    'humidity': np.random.normal(60, 10, n_samples),\n",
    "    'rotation_speed': np.random.normal(1800, 200, n_samples)\n",
    "}\n",
    "\n",
    "# Add some anomalies (outliers)\n",
    "anomaly_indices = np.random.choice(n_samples, size=50, replace=False)\n",
    "for idx in anomaly_indices:\n",
    "    data['temperature'][idx] += np.random.normal(0, 20)\n",
    "    data['vibration'][idx] += np.random.normal(0, 1)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Generated synthetic dataset with {len(df)} samples\")\n",
    "print(f\"Features: {list(df.columns)}\")\n",
    "print(\"\\nDataset summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X = df.values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Data shape: {X_scaled.shape}\")\n",
    "print(\"Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fab96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MLflow tracking URI and experiment\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "experiment_name = \"mlflow_validation_test\"\n",
    "\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    print(f\"Created new experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\"Using existing experiment: {experiment_name} (ID: {experiment_id})\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and register the model\n",
    "with mlflow.start_run(run_name=\"validation_test_run\") as run:\n",
    "    # Train Isolation Forest for anomaly detection\n",
    "    model = IsolationForest(\n",
    "        contamination=0.1,\n",
    "        random_state=42,\n",
    "        n_estimators=100\n",
    "    )\n",
    "    \n",
    "    model.fit(X_scaled)\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"contamination\", 0.1)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    mlflow.log_param(\"data_shape\", str(X_scaled.shape))\n",
    "    \n",
    "    # Make predictions for evaluation\n",
    "    predictions = model.predict(X_scaled)\n",
    "    anomaly_count = np.sum(predictions == -1)\n",
    "    normal_count = np.sum(predictions == 1)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"anomaly_count\", anomaly_count)\n",
    "    mlflow.log_metric(\"normal_count\", normal_count)\n",
    "    mlflow.log_metric(\"anomaly_ratio\", anomaly_count / len(predictions))\n",
    "    \n",
    "    # Save feature names for later validation\n",
    "    feature_names = list(df.columns)\n",
    "    mlflow.log_param(\"feature_names\", str(feature_names))\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, \n",
    "        \"model\",\n",
    "        registered_model_name=\"anomaly_detector_validation\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Model trained and logged successfully!\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Anomalies detected: {anomaly_count}/{len(predictions)} ({100*anomaly_count/len(predictions):.1f}%)\")\n",
    "    print(f\"Feature names: {feature_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9db26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model registration\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"anomaly_detector_validation\"\n",
    "\n",
    "try:\n",
    "    model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    print(f\"\\nModel '{model_name}' registered successfully!\")\n",
    "    print(f\"Total versions: {len(model_versions)}\")\n",
    "    \n",
    "    for version in model_versions:\n",
    "        print(f\"  Version {version.version}: {version.current_stage} (Run: {version.run_id})\")\n",
    "    \n",
    "    # Get the latest version\n",
    "    if model_versions:\n",
    "        latest_version = max([int(v.version) for v in model_versions])\n",
    "        print(f\"\\nLatest version: {latest_version}\")\n",
    "        print(f\"Ready for API testing with model_name='{model_name}' and model_version='{latest_version}'\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error checking model registration: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
