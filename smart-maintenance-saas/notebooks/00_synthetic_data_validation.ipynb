{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "# MLflow Validation Test - Self-Contained Model Registration\n",
    "\n",
    "This notebook generates synthetic data and registers a simple model to validate our MLflow infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic sensor data matching our database schema\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define realistic sensor characteristics based on our database\n",
    "sensor_types = {\n",
    "    'vibration': {'min': 28, 'max': 82, 'avg': 60, 'unit': 'mm/s'},\n",
    "    'pressure': {'min': 29, 'max': 55, 'avg': 46, 'unit': 'kPa'},\n",
    "    'temperature': {'min': 11, 'max': 89, 'avg': 53, 'unit': 'C'},\n",
    "    'humidity': {'min': 32, 'max': 88, 'avg': 66, 'unit': '%'},\n",
    "    'voltage': {'min': 21, 'max': 58, 'avg': 43, 'unit': 'V'}\n",
    "}\n",
    "\n",
    "n_samples = 1000\n",
    "sensor_features = []\n",
    "feature_names = []\n",
    "\n",
    "# Generate realistic features for each sensor type\n",
    "for sensor_type, params in sensor_types.items():\n",
    "    # Normal operation: centered around average with some variance\n",
    "    normal_std = (params['max'] - params['min']) * 0.15  # 15% of range as std\n",
    "    normal_data = np.random.normal(params['avg'], normal_std, int(n_samples * 0.9))\n",
    "    \n",
    "    # Anomalous data: values near limits or outside normal range\n",
    "    anomaly_low = np.random.uniform(params['min'], params['avg'] - 2*normal_std, int(n_samples * 0.05))\n",
    "    anomaly_high = np.random.uniform(params['avg'] + 2*normal_std, params['max'], int(n_samples * 0.05))\n",
    "    \n",
    "    # Combine normal and anomalous data\n",
    "    sensor_data = np.concatenate([normal_data, anomaly_low, anomaly_high])\n",
    "    \n",
    "    # Clip to realistic bounds\n",
    "    sensor_data = np.clip(sensor_data, params['min'], params['max'])\n",
    "    sensor_features.append(sensor_data)\n",
    "    feature_names.append(f\"{sensor_type}_{params['unit']}\")\n",
    "\n",
    "# Stack features horizontally\n",
    "X_synthetic = np.column_stack(sensor_features)\n",
    "\n",
    "# Create labels: 0 for normal (first 90%), 1 for anomalous (last 10%)\n",
    "y_synthetic = np.concatenate([\n",
    "    np.zeros(int(n_samples * 0.9)),  # Normal\n",
    "    np.ones(int(n_samples * 0.1))    # Anomalous\n",
    "])\n",
    "\n",
    "# Shuffle the data to mix normal and anomalous samples\n",
    "shuffle_idx = np.random.permutation(len(X_synthetic))\n",
    "X_synthetic = X_synthetic[shuffle_idx]\n",
    "y_synthetic = y_synthetic[shuffle_idx]\n",
    "\n",
    "print(f\"Generated {len(X_synthetic)} realistic sensor samples\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Normal samples: {(y_synthetic == 0).sum()}, Anomalous samples: {(y_synthetic == 1).sum()}\")\n",
    "print(\"\\nSample ranges:\")\n",
    "for i, (name, sensor_type) in enumerate(zip(feature_names, sensor_types.keys())):\n",
    "    print(f\"  {name}: {X_synthetic[:, i].min():.1f} - {X_synthetic[:, i].max():.1f} (target: {sensor_types[sensor_type]['min']}-{sensor_types[sensor_type]['max']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Synthetic_Data_Validation\")\n",
    "\n",
    "print(f\"MLflow configured to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Active experiment: {mlflow.get_experiment_by_name('Synthetic_Data_Validation')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_synthetic, y_synthetic, test_size=0.3, random_state=42, stratify=y_synthetic\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and register model with MLflow\n",
    "with mlflow.start_run(run_name=\"Realistic_Sensor_Validation_IsolationForest\") as run:\n",
    "    # Log parameters\n",
    "    contamination = 0.1\n",
    "    mlflow.log_param(\"model_type\", \"IsolationForest\")\n",
    "    mlflow.log_param(\"contamination\", contamination)\n",
    "    mlflow.log_param(\"n_samples\", n_samples)\n",
    "    mlflow.log_param(\"n_features\", len(feature_names))\n",
    "    mlflow.log_param(\"data_type\", \"realistic_synthetic\")\n",
    "    mlflow.log_param(\"sensor_types\", list(sensor_types.keys()))\n",
    "    \n",
    "    # Train model\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_train_scaled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_binary = (y_pred == -1).astype(int)  # Convert to binary (1 for anomaly)\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "    precision = precision_score(y_test, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_binary, zero_division=0)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log feature names and sensor types as artifacts\n",
    "    with open(\"/tmp/feature_names_realistic.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(feature_names))\n",
    "    mlflow.log_artifact(\"/tmp/feature_names_realistic.txt\")\n",
    "    \n",
    "    with open(\"/tmp/sensor_config.txt\", \"w\") as f:\n",
    "        for sensor_type, params in sensor_types.items():\n",
    "            f.write(f\"{sensor_type}: {params['min']}-{params['max']} {params['unit']} (avg: {params['avg']})\\n\")\n",
    "    mlflow.log_artifact(\"/tmp/sensor_config.txt\")\n",
    "    \n",
    "    # Register the model\n",
    "    model_name = \"realistic_sensor_validation_isolation_forest\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, \n",
    "        \"model\",\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model registered as: {model_name}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_binary, target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading from MLflow\n",
    "print(\"\\n=== Testing Model Loading ===\")\n",
    "try:\n",
    "    # Load the model back from MLflow\n",
    "    loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "    \n",
    "    # Test prediction with the loaded model\n",
    "    test_sample = X_test_scaled[:5]  # Test with first 5 samples\n",
    "    predictions = loaded_model.predict(test_sample)\n",
    "    \n",
    "    print(f\"Successfully loaded model: {model_name}\")\n",
    "    print(f\"Test predictions: {predictions}\")\n",
    "    print(f\"Actual labels: {y_test[:5]}\")\n",
    "    \n",
    "    # Test with a realistic sensor reading\n",
    "    realistic_sample = np.array([[60.0, 46.0, 53.0, 66.0, 43.0]])  # Normal values\n",
    "    realistic_scaled = scaler.transform(realistic_sample)\n",
    "    realistic_pred = loaded_model.predict(realistic_scaled)\n",
    "    print(f\"Normal sensor reading prediction: {realistic_pred[0]} (should be 1 for normal)\")\n",
    "    \n",
    "    print(\"‚úÖ MLflow model loading validation PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå MLflow model loading validation FAILED: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Synthetic Data Validation Summary ===\")\n",
    "print(\"‚úÖ Synthetic data generation: SUCCESS\")\n",
    "print(\"‚úÖ Model training: SUCCESS\")\n",
    "print(\"‚úÖ MLflow logging: SUCCESS\")\n",
    "print(\"‚úÖ Model registration: SUCCESS\")\n",
    "print(\"‚úÖ Model loading validation: SUCCESS\")\n",
    "print(\"\\nüéâ All validation tests passed! MLflow infrastructure is working correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
