{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {
    "papermill": {
     "duration": 0.00119,
     "end_time": "2025-09-16T20:15:41.582474",
     "exception": false,
     "start_time": "2025-09-16T20:15:41.581284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLflow Validation Test - Self-Contained Model Registration\n",
    "\n",
    "This notebook generates synthetic data and registers a simple model to validate our MLflow infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:15:41.585168Z",
     "iopub.status.busy": "2025-09-16T20:15:41.585019Z",
     "iopub.status.idle": "2025-09-16T20:15:44.895352Z",
     "shell.execute_reply": "2025-09-16T20:15:44.895023Z"
    },
    "papermill": {
     "duration": 3.31245,
     "end_time": "2025-09-16T20:15:44.895905",
     "exception": false,
     "start_time": "2025-09-16T20:15:41.583455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "MLflow tracking URI: http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:15:44.898492Z",
     "iopub.status.busy": "2025-09-16T20:15:44.898276Z",
     "iopub.status.idle": "2025-09-16T20:15:44.903652Z",
     "shell.execute_reply": "2025-09-16T20:15:44.903419Z"
    },
    "papermill": {
     "duration": 0.007077,
     "end_time": "2025-09-16T20:15:44.904076",
     "exception": false,
     "start_time": "2025-09-16T20:15:44.896999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000 realistic sensor samples\n",
      "Features: ['vibration_mm/s', 'pressure_kPa', 'temperature_C', 'humidity_%', 'voltage_V']\n",
      "Normal samples: 900, Anomalous samples: 100\n",
      "\n",
      "Sample ranges:\n",
      "  vibration_mm/s: 28.1 - 82.0 (target: 28-82)\n",
      "  pressure_kPa: 29.2 - 55.0 (target: 29-55)\n",
      "  temperature_C: 11.0 - 89.0 (target: 11-89)\n",
      "  humidity_%: 32.1 - 88.0 (target: 32-88)\n",
      "  voltage_V: 21.0 - 58.0 (target: 21-58)\n"
     ]
    }
   ],
   "source": [
    "# Generate realistic sensor data matching our database schema\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define realistic sensor characteristics based on our database\n",
    "sensor_types = {\n",
    "    'vibration': {'min': 28, 'max': 82, 'avg': 60, 'unit': 'mm/s'},\n",
    "    'pressure': {'min': 29, 'max': 55, 'avg': 46, 'unit': 'kPa'},\n",
    "    'temperature': {'min': 11, 'max': 89, 'avg': 53, 'unit': 'C'},\n",
    "    'humidity': {'min': 32, 'max': 88, 'avg': 66, 'unit': '%'},\n",
    "    'voltage': {'min': 21, 'max': 58, 'avg': 43, 'unit': 'V'}\n",
    "}\n",
    "\n",
    "n_samples = 1000\n",
    "sensor_features = []\n",
    "feature_names = []\n",
    "\n",
    "# Generate realistic features for each sensor type\n",
    "for sensor_type, params in sensor_types.items():\n",
    "    # Normal operation: centered around average with some variance\n",
    "    normal_std = (params['max'] - params['min']) * 0.15  # 15% of range as std\n",
    "    normal_data = np.random.normal(params['avg'], normal_std, int(n_samples * 0.9))\n",
    "    \n",
    "    # Anomalous data: values near limits or outside normal range\n",
    "    anomaly_low = np.random.uniform(params['min'], params['avg'] - 2*normal_std, int(n_samples * 0.05))\n",
    "    anomaly_high = np.random.uniform(params['avg'] + 2*normal_std, params['max'], int(n_samples * 0.05))\n",
    "    \n",
    "    # Combine normal and anomalous data\n",
    "    sensor_data = np.concatenate([normal_data, anomaly_low, anomaly_high])\n",
    "    \n",
    "    # Clip to realistic bounds\n",
    "    sensor_data = np.clip(sensor_data, params['min'], params['max'])\n",
    "    sensor_features.append(sensor_data)\n",
    "    feature_names.append(f\"{sensor_type}_{params['unit']}\")\n",
    "\n",
    "# Stack features horizontally\n",
    "X_synthetic = np.column_stack(sensor_features)\n",
    "\n",
    "# Create labels: 0 for normal (first 90%), 1 for anomalous (last 10%)\n",
    "y_synthetic = np.concatenate([\n",
    "    np.zeros(int(n_samples * 0.9)),  # Normal\n",
    "    np.ones(int(n_samples * 0.1))    # Anomalous\n",
    "])\n",
    "\n",
    "# Shuffle the data to mix normal and anomalous samples\n",
    "shuffle_idx = np.random.permutation(len(X_synthetic))\n",
    "X_synthetic = X_synthetic[shuffle_idx]\n",
    "y_synthetic = y_synthetic[shuffle_idx]\n",
    "\n",
    "print(f\"Generated {len(X_synthetic)} realistic sensor samples\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Normal samples: {(y_synthetic == 0).sum()}, Anomalous samples: {(y_synthetic == 1).sum()}\")\n",
    "print(\"\\nSample ranges:\")\n",
    "for i, (name, sensor_type) in enumerate(zip(feature_names, sensor_types.keys())):\n",
    "    print(f\"  {name}: {X_synthetic[:, i].min():.1f} - {X_synthetic[:, i].max():.1f} (target: {sensor_types[sensor_type]['min']}-{sensor_types[sensor_type]['max']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:15:44.906444Z",
     "iopub.status.busy": "2025-09-16T20:15:44.906336Z",
     "iopub.status.idle": "2025-09-16T20:15:46.485143Z",
     "shell.execute_reply": "2025-09-16T20:15:46.484783Z"
    },
    "papermill": {
     "duration": 1.580556,
     "end_time": "2025-09-16T20:15:46.485664",
     "exception": false,
     "start_time": "2025-09-16T20:15:44.905108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow configured to: http://mlflow:5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active experiment: <Experiment: artifact_location='s3://yan-smart-maintenance-artifacts/1', creation_time=1758044004414, experiment_id='1', last_update_time=1758044004414, lifecycle_stage='active', name='Synthetic_Data_Validation', tags={}>\n"
     ]
    }
   ],
   "source": [
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "mlflow.set_experiment(\"Synthetic_Data_Validation\")\n",
    "\n",
    "print(f\"MLflow configured to: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Active experiment: {mlflow.get_experiment_by_name('Synthetic_Data_Validation')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:15:46.488287Z",
     "iopub.status.busy": "2025-09-16T20:15:46.488176Z",
     "iopub.status.idle": "2025-09-16T20:15:46.491618Z",
     "shell.execute_reply": "2025-09-16T20:15:46.491381Z"
    },
    "papermill": {
     "duration": 0.005174,
     "end_time": "2025-09-16T20:15:46.492033",
     "exception": false,
     "start_time": "2025-09-16T20:15:46.486859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (700, 5)\n",
      "Test set: (300, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_synthetic, y_synthetic, test_size=0.3, random_state=42, stratify=y_synthetic\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train_scaled.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:15:46.494477Z",
     "iopub.status.busy": "2025-09-16T20:15:46.494371Z",
     "iopub.status.idle": "2025-09-16T20:16:16.818752Z",
     "shell.execute_reply": "2025-09-16T20:16:16.818355Z"
    },
    "papermill": {
     "duration": 30.326303,
     "end_time": "2025-09-16T20:16:16.819456",
     "exception": false,
     "start_time": "2025-09-16T20:15:46.493153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:15:46 WARNING mlflow.tracking.context.registry: Encountered unexpected error during resolving tags: 'getpwuid(): uid not found: 1000'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/09/16 20:16:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'realistic_sensor_validation_isolation_forest'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 20:16:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: realistic_sensor_validation_isolation_forest, version 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'realistic_sensor_validation_isolation_forest'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered as: realistic_sensor_validation_isolation_forest\n",
      "Run ID: 64535d709de2458396986ff9f939517a\n",
      "Accuracy: 0.9800\n",
      "Precision: 0.8750\n",
      "Recall: 0.9333\n",
      "F1-Score: 0.9032\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      0.99      0.99       270\n",
      "     Anomaly       0.88      0.93      0.90        30\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.93      0.96      0.95       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Realistic_Sensor_Validation_IsolationForest at: http://mlflow:5000/#/experiments/1/runs/64535d709de2458396986ff9f939517a\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Train and register model with MLflow\n",
    "with mlflow.start_run(run_name=\"Realistic_Sensor_Validation_IsolationForest\") as run:\n",
    "    # Log parameters\n",
    "    contamination = 0.1\n",
    "    mlflow.log_param(\"model_type\", \"IsolationForest\")\n",
    "    mlflow.log_param(\"contamination\", contamination)\n",
    "    mlflow.log_param(\"n_samples\", n_samples)\n",
    "    mlflow.log_param(\"n_features\", len(feature_names))\n",
    "    mlflow.log_param(\"data_type\", \"realistic_synthetic\")\n",
    "    mlflow.log_param(\"sensor_types\", list(sensor_types.keys()))\n",
    "    \n",
    "    # Train model\n",
    "    model = IsolationForest(contamination=contamination, random_state=42)\n",
    "    model.fit(X_train_scaled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_binary = (y_pred == -1).astype(int)  # Convert to binary (1 for anomaly)\n",
    "    \n",
    "    # Calculate comprehensive metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "    precision = precision_score(y_test, y_pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_binary, zero_division=0)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log feature names and sensor types as artifacts\n",
    "    with open(\"/tmp/feature_names_realistic.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(feature_names))\n",
    "    mlflow.log_artifact(\"/tmp/feature_names_realistic.txt\")\n",
    "    \n",
    "    with open(\"/tmp/sensor_config.txt\", \"w\") as f:\n",
    "        for sensor_type, params in sensor_types.items():\n",
    "            f.write(f\"{sensor_type}: {params['min']}-{params['max']} {params['unit']} (avg: {params['avg']})\\n\")\n",
    "    mlflow.log_artifact(\"/tmp/sensor_config.txt\")\n",
    "    \n",
    "    # Register the model\n",
    "    model_name = \"realistic_sensor_validation_isolation_forest\"\n",
    "    mlflow.sklearn.log_model(\n",
    "        model, \n",
    "        \"model\",\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "    \n",
    "    print(f\"Model registered as: {model_name}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_binary, target_names=['Normal', 'Anomaly']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:16:16.822672Z",
     "iopub.status.busy": "2025-09-16T20:16:16.822556Z",
     "iopub.status.idle": "2025-09-16T20:16:21.898439Z",
     "shell.execute_reply": "2025-09-16T20:16:21.898149Z"
    },
    "papermill": {
     "duration": 5.077926,
     "end_time": "2025-09-16T20:16:21.898944",
     "exception": false,
     "start_time": "2025-09-16T20:16:16.821018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Model Loading ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:   0%|                                                                                                | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 1/5 [00:00<00:01,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                                                      | 1/5 [00:00<00:01,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 2/5 [00:00<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                    | 2/5 [00:00<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 3/5 [00:00<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 4/5 [00:00<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model: realistic_sensor_validation_isolation_forest\n",
      "Test predictions: [1 1 1 1 1]\n",
      "Actual labels: [0. 0. 0. 0. 0.]\n",
      "Normal sensor reading prediction: 1 (should be 1 for normal)\n",
      "‚úÖ MLflow model loading validation PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test model loading from MLflow\n",
    "print(\"\\n=== Testing Model Loading ===\")\n",
    "try:\n",
    "    # Load the model back from MLflow\n",
    "    loaded_model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "    \n",
    "    # Test prediction with the loaded model\n",
    "    test_sample = X_test_scaled[:5]  # Test with first 5 samples\n",
    "    predictions = loaded_model.predict(test_sample)\n",
    "    \n",
    "    print(f\"Successfully loaded model: {model_name}\")\n",
    "    print(f\"Test predictions: {predictions}\")\n",
    "    print(f\"Actual labels: {y_test[:5]}\")\n",
    "    \n",
    "    # Test with a realistic sensor reading\n",
    "    realistic_sample = np.array([[60.0, 46.0, 53.0, 66.0, 43.0]])  # Normal values\n",
    "    realistic_scaled = scaler.transform(realistic_sample)\n",
    "    realistic_pred = loaded_model.predict(realistic_scaled)\n",
    "    print(f\"Normal sensor reading prediction: {realistic_pred[0]} (should be 1 for normal)\")\n",
    "    \n",
    "    print(\"‚úÖ MLflow model loading validation PASSED\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå MLflow model loading validation FAILED: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-16T20:16:21.902904Z",
     "iopub.status.busy": "2025-09-16T20:16:21.902804Z",
     "iopub.status.idle": "2025-09-16T20:16:21.904819Z",
     "shell.execute_reply": "2025-09-16T20:16:21.904577Z"
    },
    "papermill": {
     "duration": 0.00426,
     "end_time": "2025-09-16T20:16:21.905285",
     "exception": false,
     "start_time": "2025-09-16T20:16:21.901025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Synthetic Data Validation Summary ===\n",
      "‚úÖ Synthetic data generation: SUCCESS\n",
      "‚úÖ Model training: SUCCESS\n",
      "‚úÖ MLflow logging: SUCCESS\n",
      "‚úÖ Model registration: SUCCESS\n",
      "‚úÖ Model loading validation: SUCCESS\n",
      "\n",
      "üéâ All validation tests passed! MLflow infrastructure is working correctly.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Synthetic Data Validation Summary ===\")\n",
    "print(\"‚úÖ Synthetic data generation: SUCCESS\")\n",
    "print(\"‚úÖ Model training: SUCCESS\")\n",
    "print(\"‚úÖ MLflow logging: SUCCESS\")\n",
    "print(\"‚úÖ Model registration: SUCCESS\")\n",
    "print(\"‚úÖ Model loading validation: SUCCESS\")\n",
    "print(\"\\nüéâ All validation tests passed! MLflow infrastructure is working correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.757854,
   "end_time": "2025-09-16T20:16:22.621094",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/00_synthetic_data_validation.ipynb",
   "output_path": "notebooks/00_synthetic_data_validation_output.ipynb",
   "parameters": {},
   "start_time": "2025-09-16T20:15:40.863240",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}