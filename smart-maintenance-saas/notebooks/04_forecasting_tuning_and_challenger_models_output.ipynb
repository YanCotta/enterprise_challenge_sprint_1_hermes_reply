{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61c06213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:55:33.120918Z",
     "iopub.status.busy": "2025-08-17T14:55:33.120752Z",
     "iopub.status.idle": "2025-08-17T14:55:38.622587Z",
     "shell.execute_reply": "2025-08-17T14:55:38.622322Z"
    },
    "papermill": {
     "duration": 5.5044,
     "end_time": "2025-08-17T14:55:38.623155",
     "exception": false,
     "start_time": "2025-08-17T14:55:33.118755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI set to: http://mlflow:5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from prophet import Prophet\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import logging\n",
    "import os\n",
    "from apps.ml.features import SensorFeatureTransformer\n",
    "\n",
    "logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.ERROR)\n",
    "\n",
    "tracking_uri = \"http://mlflow:5000\" if os.getenv(\"DOCKER_ENV\") == \"true\" else \"http://localhost:5000\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment(\"Forecasting Models\")\n",
    "\n",
    "print(f\"MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1bfc18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:55:38.625577Z",
     "iopub.status.busy": "2025-08-17T14:55:38.625332Z",
     "iopub.status.idle": "2025-08-17T14:55:38.654414Z",
     "shell.execute_reply": "2025-08-17T14:55:38.654129Z"
    },
    "papermill": {
     "duration": 0.030651,
     "end_time": "2025-08-17T14:55:38.654905",
     "exception": false,
     "start_time": "2025-08-17T14:55:38.624254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for sensor: sensor-001\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preparation (Consistent for both models) ---\n",
    "df = pd.read_csv('data/sensor_data.csv', parse_dates=['timestamp'])\n",
    "df['timestamp'] = df['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "sensor_id = 'sensor-001'\n",
    "df_sensor = df[df['sensor_id'] == sensor_id].copy()\n",
    "\n",
    "# 80/20 Train/Test Split\n",
    "split_point = int(len(df_sensor) * 0.8)\n",
    "train_df_raw = df_sensor.iloc[:split_point]\n",
    "test_df_raw = df_sensor.iloc[split_point:]\n",
    "\n",
    "y_true = test_df_raw['value'].values\n",
    "\n",
    "print(f\"Data prepared for sensor: {sensor_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7428e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:55:38.656908Z",
     "iopub.status.busy": "2025-08-17T14:55:38.656810Z",
     "iopub.status.idle": "2025-08-17T14:55:40.748775Z",
     "shell.execute_reply": "2025-08-17T14:55:40.748512Z"
    },
    "papermill": {
     "duration": 2.093493,
     "end_time": "2025-08-17T14:55:40.749276",
     "exception": false,
     "start_time": "2025-08-17T14:55:38.655783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Prophet Tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:38 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Prophet_Tuning_cps_0.01_sps_1.0 at: http://mlflow:5000/#/experiments/2/runs/dbc96c88a34e47e39b95e34856060941\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "üèÉ View run Prophet_Tuning_cps_0.01_sps_5.0 at: http://mlflow:5000/#/experiments/2/runs/d23ac586a6194adda1ed639b7c46aa05\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Prophet_Tuning_cps_0.01_sps_10.0 at: http://mlflow:5000/#/experiments/2/runs/6f0d7fa86ff944f49566565d5f52bc10\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "üèÉ View run Prophet_Tuning_cps_0.05_sps_1.0 at: http://mlflow:5000/#/experiments/2/runs/6f0d9f58dd6d4b6c992c8864dc20216c\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Prophet_Tuning_cps_0.05_sps_5.0 at: http://mlflow:5000/#/experiments/2/runs/f2deb2783b3241858ad36c24aa22b65d\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "üèÉ View run Prophet_Tuning_cps_0.05_sps_10.0 at: http://mlflow:5000/#/experiments/2/runs/ffaa7c4c489847aaad72f3c4d5ae5e74\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Prophet_Tuning_cps_0.1_sps_1.0 at: http://mlflow:5000/#/experiments/2/runs/3b96d5382a744d4cabc1a6af4a37a206\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "üèÉ View run Prophet_Tuning_cps_0.1_sps_5.0 at: http://mlflow:5000/#/experiments/2/runs/110305c825ac44d7971ff95f039a985c\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Prophet_Tuning_cps_0.1_sps_10.0 at: http://mlflow:5000/#/experiments/2/runs/619f991b620b44d8bda6838fe48eb70f\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "Best Prophet MAE: 2.8258 with params: {'changepoint_prior_scale': 0.1, 'seasonality_prior_scale': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Prophet Hyperparameter Tuning ---\n",
    "print(\"\\n--- Starting Prophet Tuning ---\")\n",
    "\n",
    "# Define a simple grid of hyperparameters to test\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.01, 0.05, 0.1],\n",
    "    'seasonality_prior_scale': [1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "best_mae = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "# Prepare data for Prophet\n",
    "train_df_prophet = train_df_raw[['timestamp', 'value']].rename(columns={'timestamp': 'ds', 'value': 'y'})\n",
    "\n",
    "for cps in param_grid['changepoint_prior_scale']:\n",
    "    for sps in param_grid['seasonality_prior_scale']:\n",
    "        with mlflow.start_run(run_name=f\"Prophet_Tuning_cps_{cps}_sps_{sps}\", nested=True):\n",
    "            params = {'changepoint_prior_scale': cps, 'seasonality_prior_scale': sps}\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param(\"model_type\", \"Prophet_Tuned\")\n",
    "\n",
    "            model = Prophet(**params, daily_seasonality=True, weekly_seasonality=False, yearly_seasonality=False)\n",
    "            model.fit(train_df_prophet)\n",
    "            \n",
    "            future_df = model.make_future_dataframe(periods=len(test_df_raw), freq='5min')\n",
    "            forecast_df = model.predict(future_df)\n",
    "            y_pred = forecast_df['yhat'][-len(test_df_raw):].values\n",
    "            \n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mlflow.log_metric(\"mae\", mae)\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_params = params\n",
    "                # Log the best model so far\n",
    "                mlflow.prophet.log_model(model, \"best_prophet_model\")\n",
    "                mlflow.set_tag(\"status\", \"best_candidate\")\n",
    "\n",
    "print(f\"Best Prophet MAE: {best_mae:.4f} with params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969613a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T14:55:40.752851Z",
     "iopub.status.busy": "2025-08-17T14:55:40.752713Z",
     "iopub.status.idle": "2025-08-17T14:55:43.355854Z",
     "shell.execute_reply": "2025-08-17T14:55:43.355576Z"
    },
    "papermill": {
     "duration": 2.605493,
     "end_time": "2025-08-17T14:55:43.356411",
     "exception": false,
     "start_time": "2025-08-17T14:55:40.750918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/apps/ml/features.py:75: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.ffill().bfill())\n",
      "/app/apps/ml/features.py:75: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.ffill().bfill())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting LightGBM Challenger Model ---\n",
      "NaN values in X_train: 0\n",
      "NaN values in y_train: 0\n",
      "NaN values in X_test: 0\n",
      "NaN values in y_test: 0\n",
      "Final training set size: 479\n",
      "Final test set size: 119\n",
      "LightGBM MAE: 3.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/08/17 14:55:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'lightgbm_forecaster_challenger'.\n",
      "2025/08/17 14:55:43 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lightgbm_forecaster_challenger, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LightGBM_Challenger_v1 at: http://mlflow:5000/#/experiments/2/runs/7384902b9eaa44218917a15bb8abe807\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "\n",
      "--- Experiment session complete! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'lightgbm_forecaster_challenger'.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Challenger Model: LightGBM with Lag Features ---\n",
    "print(\"\\n--- Starting LightGBM Challenger Model ---\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LightGBM_Challenger_v1\"):\n",
    "    mlflow.log_param(\"model_type\", \"LightGBM\")\n",
    "    \n",
    "    # --- Feature Engineering ---\n",
    "    # Create lag features for forecasting the next value\n",
    "    feature_transformer = SensorFeatureTransformer(n_lags=12, scale_columns=['value'])\n",
    "    \n",
    "    # Transform train data\n",
    "    X_train_transformed = feature_transformer.fit_transform(train_df_raw)\n",
    "    # Create target: next value (shift -1 means we predict the next value)\n",
    "    y_train_full = train_df_raw['value'].shift(-1)\n",
    "    \n",
    "    # Remove the last row since it doesn't have a target (NaN after shift)\n",
    "    X_train_clean = X_train_transformed.iloc[:-1]\n",
    "    y_train_clean = y_train_full.iloc[:-1]\n",
    "    \n",
    "    # Transform test data\n",
    "    X_test_transformed = feature_transformer.transform(test_df_raw)\n",
    "    y_test_full = test_df_raw['value'].shift(-1)\n",
    "    \n",
    "    # Remove the last row since it doesn't have a target\n",
    "    X_test_clean = X_test_transformed.iloc[:-1]\n",
    "    y_test_clean = y_test_full.iloc[:-1]\n",
    "    \n",
    "    # Check for any remaining NaN values and handle them\n",
    "    print(f\"NaN values in X_train: {X_train_clean.isna().sum().sum()}\")\n",
    "    print(f\"NaN values in y_train: {y_train_clean.isna().sum()}\")\n",
    "    print(f\"NaN values in X_test: {X_test_clean.isna().sum().sum()}\")\n",
    "    print(f\"NaN values in y_test: {y_test_clean.isna().sum()}\")\n",
    "    \n",
    "    # Drop any remaining NaN rows\n",
    "    if X_train_clean.isna().any().any() or y_train_clean.isna().any():\n",
    "        valid_train_idx = ~(X_train_clean.isna().any(axis=1) | y_train_clean.isna())\n",
    "        X_train_clean = X_train_clean[valid_train_idx]\n",
    "        y_train_clean = y_train_clean[valid_train_idx]\n",
    "        print(f\"Dropped {(~valid_train_idx).sum()} training rows with NaN\")\n",
    "    \n",
    "    if X_test_clean.isna().any().any() or y_test_clean.isna().any():\n",
    "        valid_test_idx = ~(X_test_clean.isna().any(axis=1) | y_test_clean.isna())\n",
    "        X_test_clean = X_test_clean[valid_test_idx]\n",
    "        y_test_clean = y_test_clean[valid_test_idx]\n",
    "        print(f\"Dropped {(~valid_test_idx).sum()} test rows with NaN\")\n",
    "    \n",
    "    print(f\"Final training set size: {len(X_train_clean)}\")\n",
    "    print(f\"Final test set size: {len(X_test_clean)}\")\n",
    "    \n",
    "    # --- Model Training ---\n",
    "    lgbm = lgb.LGBMRegressor(random_state=42, verbosity=-1)\n",
    "    mlflow.log_params(lgbm.get_params())\n",
    "    lgbm.fit(X_train_clean, y_train_clean)\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    y_pred_lgbm = lgbm.predict(X_test_clean)\n",
    "    mae_lgbm = mean_absolute_error(y_test_clean, y_pred_lgbm)\n",
    "    mlflow.log_metric(\"mae\", mae_lgbm)\n",
    "    \n",
    "    print(f\"LightGBM MAE: {mae_lgbm:.4f}\")\n",
    "\n",
    "    # --- Log Model ---\n",
    "    mlflow.lightgbm.log_model(lgbm, \"model\", registered_model_name=\"lightgbm_forecaster_challenger\")\n",
    "\n",
    "print(\"\\n--- Experiment session complete! ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.722118,
   "end_time": "2025-08-17T14:55:44.072296",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/04_forecasting_tuning_and_challenger_models.ipynb",
   "output_path": "notebooks/04_forecasting_tuning_and_challenger_models_output.ipynb",
   "parameters": {},
   "start_time": "2025-08-17T14:55:32.350178",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}